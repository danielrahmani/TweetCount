{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries and initiate spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.mllib.linalg import DenseVector\n",
    "from pyspark.mllib.random import RandomRDDs\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col,udf,when,regexp_extract\n",
    "from pyspark.sql import Window\n",
    "\n",
    "\n",
    "from pyspark.sql.types import StringType,IntegerType\n",
    "\n",
    "from urllib.parse import urlparse\n",
    "import gc\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "conf = SparkConf().setAppName('clickstream')\\\n",
    "    .set('spark.driver.memoryOverhead', '2g') \\\n",
    "    .set('spark.executor.memory', '12g') \\\n",
    "    .set(\"spark.executor.instances\", \"8\") \\\n",
    "    .set('spark.executor.cores', '1') \\\n",
    "    .set(\"spark.sql.caseSensitive\", \"true\")\n",
    "#     .set('spark.driver.memory', '10g') \\\n",
    "#     .set('spark.dynamicAllocation.enabled', 'true') \\\n",
    "\n",
    "spark = SparkSession.builder.appName('clickstream').config(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Columns: 7 - Number of rows: 4917706\n",
      "Command took 152.17 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "dg = spark.read.json(r'C:\\Users\\N716307\\Downloads\\TweetCount-master\\2016\\09\\*\\*\\*\\*\\*\\*')\n",
    "dg.registerTempTable(\"dg\")\n",
    "\n",
    "df = sqlContext.sql(\"\"\"\n",
    "    SELECT request.requestHeaders.`User-Agent` as requestHeaders_User_Agent,request.requestHeaders.Referer as requestHeaders_Referer,\n",
    "    request.responseHeaders.`google-accounts-signin` as google_accounts_signin, request.documentReferer as documentReferer,\n",
    "    request.url as url, server_request.request_unixtime as request_unixtime,\n",
    "    request.ip as ip\n",
    "    FROM dg\n",
    "    \"\"\"\n",
    "                   )\n",
    "\n",
    "\n",
    "print(\"Number of Columns: {:d} - Number of rows: {:d}\".format(len(df.columns),df.count()))\n",
    "\n",
    "t1 = time.time()\n",
    "print('Command took {:.2f} seconds'.format(t1-t0))\n",
    "\n",
    "del dg\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# user agent --> OS\n",
    "df = df.withColumn('requestHeaders_User_Agent', regexp_extract(col('requestHeaders_User_Agent'), r\"\\((\\w+)([^\\)]+)\\)\",1))\n",
    "\n",
    "# extract the google account of the user (if logged in)\n",
    "df = df.withColumn('google_accounts_signin', regexp_extract(col('google_accounts_signin'), r\"(email=\\\")([-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*))\",2))\n",
    "\n",
    "# get the hostname of the url columns\n",
    "for c in ['documentReferer','url','requestHeaders_Referer']:\n",
    "    df = df.withColumn(c,regexp_extract(col(c), r\"(www\\.)?([-a-zA-Z0-9@:%._\\+~#=]{2,256}\\.[a-z]{2,6}\\b([-a-zA-Z0-9@:%_\\+.~#?&//=]*?))\",2))\n",
    "    \n",
    "    \n",
    "df = df.select('ip',\n",
    "               'requestHeaders_User_Agent',\n",
    "               'google_accounts_signin',\n",
    "               'request_unixtime',\n",
    "               'documentReferer',\n",
    "               'url')\n",
    "\n",
    "df = df.dropDuplicates()\n",
    "\n",
    "# add a columns for how many times an ip is repeated\n",
    "w = Window.partitionBy('ip')\n",
    "df = df.withColumn('ip_count',F.count(df.ip).over(w))\n",
    "\n",
    "# transform unix time format to timestamp format\n",
    "df = df.withColumn(\"request_unixtime\",F.to_timestamp(df[\"request_unixtime\"]))\n",
    "\n",
    "\n",
    "# raw date to year, month, date, hour, etc\n",
    "df = df.withColumn('request_dayofWeek',F.dayofweek(df.request_unixtime))\n",
    "df = df.withColumn('request_dayofYear',F.dayofyear(df.request_unixtime))\n",
    "df = df.withColumn('request_day',F.dayofmonth(df.request_unixtime))\n",
    "df = df.withColumn('request_year',F.year(df.request_unixtime))\n",
    "df = df.withColumn('request_month',F.month(df.request_unixtime))\n",
    "df = df.withColumn('request_hour',F.hour(df.request_unixtime))\n",
    "\n",
    "\n",
    "df = df.withColumn('request_timeOfDay',\n",
    "                  when(df.request_hour<8,'midnight').otherwise(\n",
    "                  when(df.request_hour<12,'morning').otherwise(\n",
    "                  when(df.request_hour<18,'afternoon').otherwise(\n",
    "                  'night'))))\n",
    "\n",
    "df = df.withColumn('url_name',\n",
    "                  when(df.url.like('%amazon%'),'amazon').otherwise(\n",
    "                  when(df.url.like('%google%'),'google').otherwise(\n",
    "                  when(df.url.like('%facebook%'),'facebook').otherwise(\n",
    "                  when(df.url.like('%netflix%'),'netflix').otherwise(\n",
    "                  when(df.url.like('%priceline%'),'priceline').otherwise(\n",
    "                  'others'))))))\n",
    "\n",
    "# rel part of the Link: Used to express a typed relationship with another resource\n",
    "# df = df.withColumn('Link', regexp_extract(col('Link'), '(.)(rel=)(\\w+)',3))\n",
    "\n",
    "# response header content type\n",
    "# df = df.withColumn('responseHeader_content_type', regexp_extract(col('responseHeader_content_type'), r\"(.*?);\",1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w = Window.partitionBy('url','documentReferer')\n",
    "df = df.withColumn('url_count',F.count(df.ip).over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS for user of: amazon\n",
      "\n",
      "+-------------------------+-----+\n",
      "|requestHeaders_User_Agent|count|\n",
      "+-------------------------+-----+\n",
      "|                      X11| 2913|\n",
      "|                     null|  464|\n",
      "|                Macintosh|15981|\n",
      "|                    Linux|    1|\n",
      "|                  Windows|36303|\n",
      "+-------------------------+-----+\n",
      "\n",
      "OS for user of: netflix\n",
      "\n",
      "+-------------------------+-----+\n",
      "|requestHeaders_User_Agent|count|\n",
      "+-------------------------+-----+\n",
      "|                      X11|  224|\n",
      "|                     null|  346|\n",
      "|                Macintosh|  568|\n",
      "|                  Windows| 1204|\n",
      "+-------------------------+-----+\n",
      "\n",
      "OS for user of: priceline\n",
      "\n",
      "+-------------------------+-----+\n",
      "|requestHeaders_User_Agent|count|\n",
      "+-------------------------+-----+\n",
      "|                      X11|    1|\n",
      "|                Macintosh|   54|\n",
      "|                  Windows|  192|\n",
      "+-------------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ['amazon','netflix','priceline']:\n",
    "    print('OS for users of: {:s}\\n'.format(x))\n",
    "    df.filter(df.url_name==x).groupBy('requestHeaders_User_Agent').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day of week for users of: amazon\n",
      "\n",
      "+-----------------+-----+\n",
      "|request_dayofWeek|count|\n",
      "+-----------------+-----+\n",
      "|                3|  204|\n",
      "|                5| 6635|\n",
      "|                2| 7219|\n",
      "|                1| 9698|\n",
      "|                7|10339|\n",
      "|                4|10517|\n",
      "|                6|11050|\n",
      "+-----------------+-----+\n",
      "\n",
      "Day of week for users of: netflix\n",
      "\n",
      "+-----------------+-----+\n",
      "|request_dayofWeek|count|\n",
      "+-----------------+-----+\n",
      "|                3|   11|\n",
      "|                2|  250|\n",
      "|                5|  288|\n",
      "|                4|  392|\n",
      "|                1|  436|\n",
      "|                6|  446|\n",
      "|                7|  519|\n",
      "+-----------------+-----+\n",
      "\n",
      "Day of week for users of: priceline\n",
      "\n",
      "+-----------------+-----+\n",
      "|request_dayofWeek|count|\n",
      "+-----------------+-----+\n",
      "|                3|    1|\n",
      "|                1|   13|\n",
      "|                5|   14|\n",
      "|                2|   27|\n",
      "|                4|   34|\n",
      "|                7|   57|\n",
      "|                6|  101|\n",
      "+-----------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ['amazon','netflix','priceline']:\n",
    "    print('Day of week for users of: {:s}\\n'.format(x))\n",
    "    df.filter(df.url_name==x).groupBy('request_dayofWeek').count().orderBy('count').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dcount = df.filter((df.url_name=='amazon')|\n",
    "                   (df.url_name=='netflix')|\n",
    "                   (df.url_name=='priceline')\n",
    "                  ).groupBy(['url_name','documentReferer']).count().orderBy(col('count'),ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top refer for users of: amazon\n",
      "\n",
      "+--------+--------------------+-----+\n",
      "|url_name|     documentReferer|count|\n",
      "+--------+--------------------+-----+\n",
      "|  amazon|          amazon.com|31751|\n",
      "|  amazon|                null| 7645|\n",
      "|  amazon|          google.com| 2813|\n",
      "|  amazon|    smile.amazon.com| 1720|\n",
      "|  amazon|sellercentral.ama...|  668|\n",
      "|  amazon|    drudgereport.com|  477|\n",
      "|  amazon|        facebook.com|  446|\n",
      "|  amazon|           yahoo.com|  275|\n",
      "|  amazon|      chinatimes.com|  270|\n",
      "|  amazon|          reddit.com|  247|\n",
      "|  amazon|      login.live.com|  245|\n",
      "|  amazon|            imdb.com|  230|\n",
      "|  amazon|console.aws.amazo...|  156|\n",
      "|  amazon|           amazon.ca|  142|\n",
      "|  amazon|           amazon.es|  130|\n",
      "|  amazon|         shopbop.com|  112|\n",
      "|  amazon|             cnn.com|  107|\n",
      "|  amazon|  bbs.wenxuecity.com|  103|\n",
      "|  amazon|webmail.earthlink...|   87|\n",
      "|  amazon|us-mg6.mail.yahoo...|   85|\n",
      "+--------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "Top refer for users of: netflix\n",
      "\n",
      "+--------+--------------------+-----+\n",
      "|url_name|     documentReferer|count|\n",
      "+--------+--------------------+-----+\n",
      "| netflix|                null| 1493|\n",
      "| netflix|         netflix.com|  706|\n",
      "| netflix|          google.com|   68|\n",
      "| netflix|     dvd.netflix.com|   49|\n",
      "| netflix|            bing.com|   11|\n",
      "| netflix|    help.netflix.com|    7|\n",
      "| netflix|   chrome.google.com|    2|\n",
      "| netflix|whatthehellshould...|    1|\n",
      "| netflix|    search.yahoo.com|    1|\n",
      "| netflix|thrillermoviesstr...|    1|\n",
      "| netflix|          paypal.com|    1|\n",
      "| netflix|    search.myway.com|    1|\n",
      "| netflix|netflix.watchultr...|    1|\n",
      "+--------+--------------------+-----+\n",
      "\n",
      "Top refer for users of: priceline\n",
      "\n",
      "+---------+--------------------+-----+\n",
      "| url_name|     documentReferer|count|\n",
      "+---------+--------------------+-----+\n",
      "|priceline|       priceline.com|  135|\n",
      "|priceline|                null|   78|\n",
      "|priceline|          google.com|   18|\n",
      "|priceline|           kayak.com|    2|\n",
      "|priceline|   mg.mail.yahoo.com|    2|\n",
      "|priceline|a.cdn.intentmedia...|    2|\n",
      "|priceline|save.cheapflightn...|    2|\n",
      "|priceline|cruises.priceline...|    2|\n",
      "|priceline|   a.intentmedia.net|    1|\n",
      "|priceline|    bookingbuddy.com|    1|\n",
      "|priceline|         edreams.net|    1|\n",
      "|priceline|         trivago.com|    1|\n",
      "|priceline|          l.yimg.com|    1|\n",
      "|priceline| search.lowfares.com|    1|\n",
      "+---------+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x in ['amazon','netflix','priceline']:\n",
    "    print('Top refer for users of: {:s}\\n'.format(x))\n",
    "    dcount.filter(dcount.url_name==x).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('{:20s} {:20s} {:20s} {:20s} {:20s}'.format('column #',\"column name\",\"null count\", \"null percent\",\"distinct count\"))\n",
    "c = df.count()\n",
    "null_drop = []\n",
    "distinct_high = []\n",
    "col_number = 0\n",
    "for x,y in df.dtypes:\n",
    "    col_number += 1\n",
    "    null_count = df.filter((col(x).isNull()) | (col(x) == '')).count()\n",
    "    if y == 'string':\n",
    "        distinct_count = df.select(x).distinct().count()\n",
    "        if distinct_count > 100:\n",
    "            distinct_high.append(x)\n",
    "    else:\n",
    "        distinct_count = 0\n",
    "    if null_count*1./c > 0.2:\n",
    "        null_drop.append(x)\n",
    "    print('{:20d} {:40s} {:8d} {:6.2f}%, {:8d}'.format(col_number,x,null_count,null_count*100./c,distinct_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def ip_to_zip(ip):\n",
    "    import geoip2.database\n",
    "    reader = geoip2.database.Reader(r'C:\\Users\\N716307\\Downloads\\GeoLite2-City_20190528\\GeoLite2-City.mmdb')\n",
    "    try:\n",
    "        ip_location = reader.city(ip)\n",
    "        return int(ip_location.postal.code)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ip_to_zip(ip):\n",
    "    '''\n",
    "    Function to transform ip address to zip code.\n",
    "    This functions will be used to create a spark udf.\n",
    "    '''\n",
    "    from geolite2 import geolite2\n",
    "    if ip == None: return None\n",
    "    reader = geolite2.reader()\n",
    "    ip_location = reader.get(ip)\n",
    "    if ip_location and 'postal' in ip_location.keys():\n",
    "        try:\n",
    "            return int(ip_location['postal']['code'])\n",
    "        except:\n",
    "            return None\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform ip to zipcode\n",
    "ip_to_zip_udf = udf(ip_to_zip,IntegerType())\n",
    "# df = df.withColumn('zipcode',when(df.ip.isNotNull(),ip_to_zip_udf(df.ip)).otherwise(df.ip))\n",
    "df = df.withColumn('zipcode',ip_to_zip_udf(df.ip))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
